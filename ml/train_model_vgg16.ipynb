{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio(\"../input/ct-kidney-dataset-normal-cyst-tumor-and-stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\", output=\"dataset\", seed=1337, ratio=(.8, .1, .1), group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Import all the libraries \n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image, ImageOps  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'plotly_white'\n",
    "from plotly.subplots import make_subplots\n",
    "init_notebook_mode(connected=True)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Concatenate, Flatten, MaxPooling2D, Conv2D\n",
    "from  tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9cc9d1a3ab20ca5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "channels=3\n",
    "batch_size=25\n",
    "test_batch_size=32 \n",
    "test_steps=1\n",
    "train_path = './dataset/train'\n",
    "test_path = './dataset/test'\n",
    "val_path = './dataset/val'\n",
    "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\n",
    "def scalar(img):    \n",
    "    return img  # EfficientNet expects pixelsin range 0 to 255 so no scaling is required\n",
    "trgen=ImageDataGenerator(preprocessing_function=scalar, horizontal_flip=True)\n",
    "tvgen=ImageDataGenerator(preprocessing_function=scalar)\n",
    "train_generator=trgen.flow_from_directory( directory=train_path , target_size=(224,224), class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "test_generator=tvgen.flow_from_directory( directory=test_path, target_size=(224,224), class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "\n",
    "valid_generator=tvgen.flow_from_directory( directory=val_path, target_size=(224,224), class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "classes=list(train_generator.class_indices.keys())\n",
    "class_count=len(classes)\n",
    "train_steps=int(np.ceil(len(train_generator.labels)/batch_size))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcbb43514edf94c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top = False, weights = 'imagenet', input_shape = (224,224,3), classes = 38)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "629311a79930c372"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(base_model) \n",
    "model.add(Flatten())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a893b24d2a3866"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49b6faf102c1860e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "model.add(Dense(512,activation=('relu'))) \n",
    "model.add(Dense(256,activation=('relu'))) \n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(4,activation=('softmax'))) \n",
    "\n",
    "#Checking the final model summary\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2858aaeb817c3b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
